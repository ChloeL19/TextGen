{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chloeloughridge/anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# going to try to create my own word2vec embedding using gensim --> doing it here to save disk space\n",
    "# this version will use the text8 corpus: http://mattmahoney.net/dc/text8.zip\n",
    "\n",
    "# get gensim common_text corpus and word2vec model\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import Text8Corpus\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import Embedding\n",
    "from keras.engine import Input\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import LSTM\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03208853  0.0073209   0.00900712 -0.02446695 -0.00163148  0.01236735\n",
      " -0.00525934 -0.00280406 -0.01553019  0.02511849 -0.01539957  0.00375687\n",
      "  0.02261087 -0.00594487 -0.01470008  0.02310156  0.0162046   0.02720891\n",
      "  0.02658098  0.01824113 -0.00542357  0.01577971 -0.00168987 -0.00442371\n",
      "  0.02118422 -0.02085195 -0.01498204 -0.03048212 -0.00604855 -0.01178851\n",
      "  0.01487743  0.02653154  0.00581537  0.02968577  0.0028181  -0.04032163\n",
      "  0.01518094  0.00141743 -0.00661938  0.00267021  0.01460859 -0.00352043\n",
      "  0.02159883 -0.00027704  0.01760519  0.01320309 -0.0067158  -0.00229618\n",
      " -0.00172614  0.01947322  0.02285793  0.03966976  0.00404166  0.00447733\n",
      "  0.00125471  0.0077698  -0.00174025 -0.00056025 -0.03043101 -0.02269287\n",
      "  0.01442108 -0.02012351  0.01134761  0.0141385   0.01430881  0.00147922\n",
      " -0.01534944  0.0070199  -0.01092546 -0.03044373  0.00966285  0.00321195\n",
      "  0.00963955 -0.01097647  0.02345185 -0.00660561 -0.00932538  0.01753954\n",
      " -0.01894061  0.01131629 -0.00976695  0.02295437 -0.00805768  0.0131158\n",
      " -0.00996318 -0.00707666  0.0224581   0.0096029   0.0058287   0.02385407\n",
      " -0.00534576 -0.01210677 -0.01790253  0.01507768 -0.01709918 -0.02934464\n",
      " -0.01546939 -0.03161366  0.01376092 -0.00067497]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chloeloughridge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "# train the word2vec thing on this and create vectors for each word in vocab\n",
    "# inspiration: https://radimrehurek.com/gensim/models/word2vec.html\n",
    "path = get_tmpfile(\"word2vec.model\") # what does this do and do I need it?\n",
    "\n",
    "sentences = Text8Corpus(\"/Users/chloeloughridge/TextGeneration/text8\")\n",
    "#model.build_vocab(sentences)  # prepare the model vocabulary --> do I actually need this? i think not, but oh well\n",
    "model = Word2Vec(sentences, size=100, window=5, min_count=1, workers=4) # what are workers?\n",
    "model.save(\"word2vec.model\") # what is the advantage to doing this?\n",
    "\n",
    "print(model['debod'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gensim.models.word2vec.Text8Corpus object at 0x1a25b95358>\n",
      "1701\n",
      "words per sentence: 5207\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# how to you get to the sentences within sentences? \n",
    "# how to access the inards of a Text8Corpus object??\n",
    "print(sentences)\n",
    "counter = 0\n",
    "max_length = 0\n",
    "for sentence in sentences:\n",
    "    counter = counter + 1\n",
    "    counter_Two = 0\n",
    "    for word in sentence:\n",
    "        counter_Two += 1\n",
    "    if counter_Two > max_length:\n",
    "        max_length = counter_Two\n",
    "print(counter)\n",
    "print(\"words per sentence: {}\".format(counter_Two))\n",
    "num_sentences = counter\n",
    "print(max_length)\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chloeloughridge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "print(model['debod'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create the embedding matrix out of these word vectors: http://adventuresinmachinelearning.com/gensim-word2vec-tutorial/\n",
    "# the final result should be a matrix with shape (vocab_length, vector_dims)\n",
    "\n",
    "# convert the wv word vectors into a numpy matrix that is suitable for insertion\n",
    "# into our TensorFlow and Keras models\n",
    "vector_dim = 100\n",
    "embedding_matrix = np.zeros((len(model.wv.vocab), vector_dim))\n",
    "for i in range(len(model.wv.vocab)):\n",
    "    embedding_vector = model.wv[model.wv.index2word[i]]\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "[ 2.4928477e-02  7.4395560e-02  1.4572303e-01 -1.8398167e-01\n",
      " -4.6665215e-01  6.4402813e-01 -2.5188529e-01  9.6568957e-02\n",
      "  4.6680573e-02 -7.2990179e-01 -1.1497512e+00 -1.1323198e-01\n",
      "  2.2131431e-01  1.1476829e+00 -9.4561452e-01 -4.3233284e-01\n",
      " -2.4194548e-01  1.3786192e-01  4.4658485e-01 -5.1966548e-01\n",
      "  5.3422958e-01  4.1615844e-01  6.0259962e-01 -1.9902055e-01\n",
      " -6.8172431e-01 -6.4788491e-01 -3.9962593e-01  2.8245482e-01\n",
      " -4.1540027e-01 -4.9640048e-01 -3.3802402e-01 -1.3220663e-01\n",
      "  1.2126574e-01 -6.8992680e-01  3.8853800e-01 -3.1930414e-01\n",
      "  7.4009663e-01 -5.1237494e-02 -2.2016181e-01 -3.1909007e-01\n",
      " -3.0921206e-01 -3.0908048e-01  2.1386090e-01 -7.2627753e-01\n",
      "  2.8904381e-01 -8.2442200e-01 -1.6690338e-01  2.7233225e-01\n",
      " -7.3778182e-01  3.2042569e-01  9.9283761e-01  9.5139466e-02\n",
      " -1.1157016e+00 -2.6989222e-01  6.4047486e-01  8.2368925e-02\n",
      "  9.7128052e-01 -4.7904690e-04 -1.2479106e+00 -9.5203042e-01\n",
      "  6.4324236e-01 -6.8074816e-01  1.2045791e+00 -8.5456014e-01\n",
      " -1.1465035e-01  5.1542288e-01  2.9162962e-02  7.1793777e-01\n",
      " -2.5994372e-01 -2.9199103e-01 -6.1990803e-01 -7.5268358e-01\n",
      "  2.3967807e-01 -8.2008392e-02  7.3876776e-02  3.3092046e-01\n",
      "  3.8058326e-01  4.7386980e-01 -1.0630672e+00  1.2851539e-01\n",
      "  1.5383185e-01  3.5035208e-01 -3.4106755e-01 -8.2679737e-01\n",
      "  2.0513183e-01 -3.2700548e-01 -6.9974411e-01 -6.5674037e-01\n",
      " -4.9700028e-01  8.9039229e-02  7.8370732e-01  7.1745932e-01\n",
      "  1.7794318e-01  4.0871364e-01 -1.7557882e-01 -6.8837047e-01\n",
      "  7.0949179e-01 -1.8029830e-01 -1.2679294e-01 -1.1899350e+00]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chloeloughridge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "#MAX_SEQUENCE_LENGTH = 1000\n",
    "sentence = \"the big apple\"\n",
    "word = sentence[1]\n",
    "# this is my word_to_index map\n",
    "print(model.wv.vocab[word].index)\n",
    "# this is my word_to_vec map\n",
    "print(model['bug'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# testing iteration through word to index mapping\n",
    "word_to_index = model.wv.vocab\n",
    "#for word in word_to_index:\n",
    "    #print(word_to_index[word].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# figuring out word_to_vec_map and word_to_index map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for creating embedding layer inspired by Ng course\n",
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    \n",
    "    vocab_len = len(word_to_index) + 1                  # adding 1 to fit Keras embedding (requirement)\n",
    "    emb_dim = word_to_vec_map[\"cucumber\"].shape[0]      # define dimensionality of your GloVe word vectors (= 50)\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Initialize the embedding matrix as a numpy array of zeros of shape (vocab_len, dimensions of word vectors = emb_dim)\n",
    "    emb_matrix = np.zeros([vocab_len, emb_dim])\n",
    "    \n",
    "    # Set each row \"index\" of the embedding matrix to be the word vector representation of the \"index\"th word of the vocabulary\n",
    "    for word in word_to_index:\n",
    "        #print(word.index)\n",
    "        index = word_to_index[word].index\n",
    "        emb_matrix[index] = word_to_vec_map[word]\n",
    "\n",
    "    # Define Keras embedding layer with the correct output/input sizes, make it trainable. Use Embedding(...). Make sure to set trainable=False. \n",
    "    embedding_layer = Embedding(input_dim=vocab_len, output_dim=emb_dim, trainable=False)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Build the embedding layer, it is required before setting the weights of the embedding layer. Do not modify the \"None\".\n",
    "    embedding_layer.build((None,))\n",
    "    \n",
    "    # Set the weights of the embedding layer to the embedding matrix. Your layer is now pretrained.\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chloeloughridge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/Users/chloeloughridge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:15: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 10000, 100)\n"
     ]
    }
   ],
   "source": [
    "# building the model\n",
    "\n",
    "input_shape = (MAX_SEQUENCE_LENGTH,)\n",
    "sequence_input = Input(shape=input_shape)\n",
    "# set up the embedding layer\n",
    "embedding_layer = pretrained_embedding_layer(model, model.wv.vocab)\n",
    "# send the input through the embedding layer \n",
    "embeddings = embedding_layer(sequence_input) \n",
    "print(embeddings.shape)\n",
    "# now for the rest of the model\n",
    "X = LSTM(28)(embeddings)\n",
    "#X = Flatten()(X) --> we actually don't need the flatten layer\n",
    "X = Dense(MAX_SEQUENCE_LENGTH, activation='softmax')(X)\n",
    "\n",
    "# instantiate model\n",
    "LSTM_model = Model(inputs=sequence_input, outputs=X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "LSTM_model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam', # or is rmsprop better??\n",
    "              metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ab230e587bcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mword_oh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# set the sentence array at the index “counterTwo” to the one-hot output of previous line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0msent_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_oh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# get the input data in shape --> I think we need to convert each word to one-hot representation\n",
    "for sentence in sentences:\n",
    "    # initialize sentence array of shape [max_seq_length, vocab_length]\n",
    "    sent_array = np.zeros([MAX_SEQUENCE_LENGTH, len(model.wv.vocab)])\n",
    "    counter = 0\n",
    "    for word in sentence:\n",
    "        #print(counterTwo)\n",
    "        # get the index of that word and use to_categorical function to get one-hot\n",
    "        word_oh = keras.utils.to_categorical(model.wv.vocab[word].index, len(model.wv.vocab))\n",
    "        # set the sentence array at the index “counterTwo” to the one-hot output of previous line\n",
    "        sent_array[counter] = word_oh\n",
    "        counter = counter + 1\n",
    "\n",
    "print(sent_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-cf9cdaee35aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0msent_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0mone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for j in range(len(sent_array)):\n",
    "    one = False\n",
    "    for i in range(len(sent_array[0])):\n",
    "        if sent_array[0][i] == 1:\n",
    "            one = True\n",
    "    if not one:\n",
    "        print(\"stopped at row {}\".format(j))\n",
    "\n",
    "print(sent_array[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sample the model\n",
    "\n",
    "# choose a random starting word and then see where it goes from there?\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
